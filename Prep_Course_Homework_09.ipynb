{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manejo de errores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Con la clase creada en el módulo 7, tener en cuenta diferentes casos en que el código pudiera arrojar error. Por ejemplo, en la creación del objeto recibimos una lista de números enteros pero ¿qué pasa si se envía otro tipo de dato?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:/Users/caro_/OneDrive/Escritorio/Python-Prep/M08_clasesyOOP/herramientas_3.py\")\n",
    "\n",
    "#Agrega la ruta al archivo \"herramientas_3.py\" al sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import herramientas_3 as h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Se ha creado una lista vacía. Se esperaba una lista de núemeros enteros",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m h1\u001b[39m=\u001b[39mh\u001b[39m.\u001b[39;49mHerramientas_3(\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m \u001b[39m#Error al mandar un tipo de dato diferente al esperado\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m#Deberia decir error\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\caro_\\OneDrive\\Escritorio\\Python-Prep\\M09_errorhandling\\herramientas_3.py:8\u001b[0m, in \u001b[0;36mHerramientas_3.__init__\u001b[1;34m(self, lista_n)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mtype\u001b[39m(lista_n) \u001b[39m!=\u001b[39m \u001b[39mlist\u001b[39m):\n\u001b[0;32m      7\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlista_n \u001b[39m=\u001b[39m []\n\u001b[1;32m----> 8\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mSe ha creado una lista vacía. Se esperaba una lista de núemeros enteros\u001b[39m\u001b[39m'\u001b[39m)  \n\u001b[0;32m      9\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     10\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlista_n \u001b[39m=\u001b[39m lista_n\n",
      "\u001b[1;31mValueError\u001b[0m: Se ha creado una lista vacía. Se esperaba una lista de núemeros enteros"
     ]
    }
   ],
   "source": [
    "h1=h.Herramientas_3(\"\")\n",
    "\n",
    "#Error al mandar un tipo de dato diferente al esperado\n",
    "#Deberia decir error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas_3' from 'c:\\\\Users\\\\caro_\\\\OneDrive\\\\Escritorio\\\\Python-Prep\\\\M09_errorhandling\\\\herramientas_3.py'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(h)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) En la función que hace la conversión de grados, validar que los parámetros enviados sean los esperados, de no serlo, informar cuáles son los valores esperados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas_3' from 'c:\\\\Users\\\\caro_\\\\OneDrive\\\\Escritorio\\\\Python-Prep\\\\M09_errorhandling\\\\herramientas_3.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "h2=h.Herramientas_3([2,2,5,6,6,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los parametros esperados son: ['celsius', 'kelvin', 'farenheit']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h2.conversion_lista(3,4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Importar el modulo \"unittest\" y crear los siguientes casos de pruebas sobre la clase utilizada en el punto 2<br>\n",
    "Creacion del objeto incorrecta<br>\n",
    "Creacion correcta del objeto<br>\n",
    "Metodo valor_modal()<br>\n",
    "\n",
    "Se puede usar \"raise ValueError()\" en la creación de la clase para verificar el error. Investigar sobre esta funcionalidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas_3' from 'c:\\\\Users\\\\caro_\\\\OneDrive\\\\Escritorio\\\\Python-Prep\\\\M09_errorhandling\\\\herramientas_3.py'>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas_3' from 'c:\\\\Users\\\\caro_\\\\OneDrive\\\\Escritorio\\\\Python-Prep\\\\M09_errorhandling\\\\herramientas_3.py'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CasosDePruebas(unittest.TestCase):\n",
    "\n",
    "    def test_objeto_incorrecto(self):\n",
    "        dato=\"hola\"\n",
    "        self.assertRaises(ValueError,h.Herramientas_3,dato)\n",
    "\n",
    "    def test_objeto_correcto(self):\n",
    "        dato=[1,2,3,3]\n",
    "        h2=h.Herramientas_3(dato)\n",
    "        self.assertEqual(h2.lista_n,dato)\n",
    "\n",
    "    def test_repetidos(self):\n",
    "        lis=[1,3,1,2]\n",
    "        h2=h.Herramientas_3(lis)\n",
    "        resultado=h2.mas_repetido()\n",
    "        r2=\"Mayor cantidad de repeticiones: 2\"\n",
    "        r3=\"El numero más repetido es: 1\"\n",
    "        self.assertEqual(resultado,(r2 + \"\\n\" + r3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_objeto_correcto (__main__.CasosDePruebas) ... ok\n",
      "test_objeto_incorrecto (__main__.CasosDePruebas) ... ok\n",
      "test_repetidos (__main__.CasosDePruebas) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.005s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1b04d4d1240>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[\"\"],verbosity=2,exit=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Probar una creación incorrecta y visualizar la salida del \"raise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Se ha creado una lista vacía. Se esperaba una lista de núemeros enteros",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m h3\u001b[39m=\u001b[39mh\u001b[39m.\u001b[39;49mHerramientas_3(\u001b[39m\"\u001b[39;49m\u001b[39mmundo\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\caro_\\OneDrive\\Escritorio\\Python-Prep\\M09_errorhandling\\herramientas_3.py:8\u001b[0m, in \u001b[0;36mHerramientas_3.__init__\u001b[1;34m(self, lista_n)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mtype\u001b[39m(lista_n) \u001b[39m!=\u001b[39m \u001b[39mlist\u001b[39m):\n\u001b[0;32m      7\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlista_n \u001b[39m=\u001b[39m []\n\u001b[1;32m----> 8\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mSe ha creado una lista vacía. Se esperaba una lista de núemeros enteros\u001b[39m\u001b[39m'\u001b[39m)  \n\u001b[0;32m      9\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     10\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlista_n \u001b[39m=\u001b[39m lista_n\n",
      "\u001b[1;31mValueError\u001b[0m: Se ha creado una lista vacía. Se esperaba una lista de núemeros enteros"
     ]
    }
   ],
   "source": [
    "h3=h.Herramientas_3(\"mundo\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Agregar casos de pruebas para el método verifica_primos() realizando el cambio en la clase, para que devuelva una lista de True o False en función de que el elemento en la posisicón sea o no primo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas_3' from 'c:\\\\Users\\\\caro_\\\\OneDrive\\\\Escritorio\\\\Python-Prep\\\\M09_errorhandling\\\\herramientas_3.py'>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas_3' from 'c:\\\\Users\\\\caro_\\\\OneDrive\\\\Escritorio\\\\Python-Prep\\\\M09_errorhandling\\\\herramientas_3.py'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PruebaPrimo(unittest.TestCase):\n",
    "\n",
    "    def test_verificar_primos(self):\n",
    "        lis_1=[5,7,8,9,11,12]\n",
    "        h4=h.Herramientas_3(lis_1)\n",
    "        v_primos=h4.verificar_primo()\n",
    "        primos_esperado=[True,True,False,False,True,False]\n",
    "        self.assertEqual(v_primos,primos_esperado)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_conversion_grados (__main__.PruebaMetodoConversion) ... ok\n",
      "test_verificar_primos (__main__.PruebaPrimo) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.002s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x215d3287f10>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[\"\"],verbosity=2,exit=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Agregar casos de pruebas para el método conversion_grados()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas_3' from 'c:\\\\Users\\\\caro_\\\\OneDrive\\\\Escritorio\\\\Python-Prep\\\\M09_errorhandling\\\\herramientas_3.py'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PruebaMetodoConversion(unittest.TestCase):\n",
    "\n",
    "    def test_conversion_grados(self):\n",
    "        lis_2=[30,40,60,80,100]\n",
    "        h5=h.Herramientas_3(lis_2)\n",
    "        v_conversion=h5.conversion_lista(\"celsius\",\"kelvin\")\n",
    "        conversion_esperado=[303.15,313.15,333.15,353.15,373.15]\n",
    "        self.assertEqual(v_conversion,conversion_esperado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_conversion_grados (__main__.PruebaMetodoConversion) ... ok\n",
      "test_verificar_primos (__main__.PruebaPrimo) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.002s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x215d3286c50>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[\"\"],verbosity=2,exit=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Agregar casos de pruebas para el método factorial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'herramientas_3' from 'c:\\\\Users\\\\caro_\\\\OneDrive\\\\Escritorio\\\\Python-Prep\\\\M09_errorhandling\\\\herramientas_3.py'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PruebaFactorial(unittest.TestCase):\n",
    "    \n",
    "    def test_factorial(self):\n",
    "        lis_3=[1,2,3,4]\n",
    "        h6=h.Herramientas_3(lis_3)\n",
    "        v_factorial=h6.factorial_lista()\n",
    "        factorial_esperado=[1,2,6,24]\n",
    "        self.assertEqual(v_factorial,factorial_esperado)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_factorial (__main__.PruebaFactorial) ... ok\n",
      "test_conversion_grados (__main__.PruebaMetodoConversion) ... ok\n",
      "test_verificar_primos (__main__.PruebaPrimo) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.004s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x215d326f970>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[\"\"],verbosity=2,exit=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c85384e4cb51c8b72350f3a8712cc8351fdc3955e32a27f9b60c6242ab125f01"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
